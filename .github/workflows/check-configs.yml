name: V2Ray Config Checker Pipeline

on:
  workflow_dispatch:
    inputs:
      workers:
        description: 'Number of parallel workers'
        required: false
        default: '4'
        type: choice
        options:
          - '2'
          - '4'
          - '6'
          - '8'
          - '10'
      core:
        description: 'Proxy core for testing'
        required: false
        default: 'xray'
        type: choice
        options:
          - 'xray'
          - 'singbox'
          - 'mihomo'
          - 'v2ray'
  schedule:
    - cron: '0 0,5,10,15,20 * * *'    # Every 2h30m (on the hour)
    - cron: '30 2,7,12,17,22 * * *'    # Every 2h30m (on the half hour)

permissions:
  contents: write

env:
  WORKER_COUNT: ${{ github.event.inputs.workers || '4' }}
  PROXY_CORE: ${{ github.event.inputs.core || 'xray' }}
  GO_VERSION: '1.22'
  XRAY_VERSION: '1.8.24'
  SINGBOX_VERSION: '1.11.0'
  MIHOMO_VERSION: 'v1.19.0'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ARCHITECTURE: Master â†’ Workers â†’ Collector
#
#  Master:    Fetch subs, clean, deduplicate, split into chunks
#  Workers:   Each tests a chunk (ping + speed) in parallel
#  Collector: Merge all worker results, push to repo
#
#  Each worker runs on its own ubuntu-latest runner (2 vCPUs)
#  4 workers = 8 vCPUs total, 10 workers = 20 vCPUs total
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

jobs:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 1: MASTER â€” Fetch, Clean, Split
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  master:
    name: "ğŸ”· Master: Prepare & Split"
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      matrix: ${{ steps.split.outputs.matrix }}
      total_configs: ${{ steps.split.outputs.total_configs }}
      chunk_count: ${{ steps.split.outputs.chunk_count }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Build Application
        run: |
          go mod tidy
          go build -ldflags="-s -w" -o configchecker ./cmd/
          echo "âœ… Build OK"

      - name: "Step 1: Fetch Subscriptions"
        env:
          RUNNER_NAME: master
        run: |
          echo "ğŸ“¡ Fetching subscription configs..."
          ./configchecker fetch

      - name: "Step 2: Clean & Deduplicate"
        env:
          RUNNER_NAME: master
        run: |
          echo "ğŸ§¹ Cleaning and deduplicating configs..."
          ./configchecker clean

      - name: "Step 3: Split into Worker Chunks"
        id: split
        env:
          RUNNER_NAME: master
        run: |
          echo "âœ‚ï¸ Splitting configs into $WORKER_COUNT chunks..."
          ./configchecker split $WORKER_COUNT

          # Verify outputs
          echo ""
          echo "â•â•â• CHUNK SUMMARY â•â•â•"
          for f in chunks/chunk_*.txt; do
            if [ -f "$f" ]; then
              echo "  $(basename $f): $(wc -l < $f) configs"
            fi
          done
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Upload Config Chunks
        uses: actions/upload-artifact@v4
        with:
          name: config-chunks
          path: chunks/
          retention-days: 1
          if-no-files-found: error

      - name: Upload Master Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-master
          path: logs/
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload Build Binary
        uses: actions/upload-artifact@v4
        with:
          name: configchecker-binary
          path: configchecker
          retention-days: 1

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 2: WORKERS â€” Test Configs in Parallel
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  worker:
    name: "ğŸŸ¢ Worker ${{ matrix.chunk_id }}"
    needs: master
    runs-on: ubuntu-latest
    timeout-minutes: 150
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.master.outputs.matrix) }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Download Binary
        uses: actions/download-artifact@v4
        with:
          name: configchecker-binary

      - name: Make Binary Executable
        run: chmod +x ./configchecker

      - name: Install Proxy Core
        run: |
          echo "ğŸ“¦ Installing proxy core: $PROXY_CORE"
          case "$PROXY_CORE" in
            xray)
              wget -q "https://github.com/XTLS/Xray-core/releases/download/v${{ env.XRAY_VERSION }}/Xray-linux-64.zip" -O /tmp/core.zip
              sudo unzip -o /tmp/core.zip -d /usr/local/bin/ xray
              sudo chmod +x /usr/local/bin/xray
              echo "âœ… $(xray version | head -1)"
              ;;
            singbox)
              wget -q "https://github.com/SagerNet/sing-box/releases/download/v${{ env.SINGBOX_VERSION }}/sing-box-${{ env.SINGBOX_VERSION }}-linux-amd64.tar.gz" -O /tmp/core.tar.gz
              tar -xzf /tmp/core.tar.gz -C /tmp/
              sudo mv /tmp/sing-box-${{ env.SINGBOX_VERSION }}-linux-amd64/sing-box /usr/local/bin/
              sudo chmod +x /usr/local/bin/sing-box
              echo "âœ… $(sing-box version | head -1)"
              ;;
            mihomo)
              wget -q "https://github.com/MetaCubeX/mihomo/releases/download/${{ env.MIHOMO_VERSION }}/mihomo-linux-amd64-${{ env.MIHOMO_VERSION }}.gz" -O /tmp/mihomo.gz
              gunzip /tmp/mihomo.gz
              sudo mv /tmp/mihomo /usr/local/bin/mihomo
              sudo chmod +x /usr/local/bin/mihomo
              echo "âœ… $(mihomo -v | head -1)"
              ;;
            v2ray)
              wget -q "https://github.com/v2fly/v2ray-core/releases/latest/download/v2ray-linux-64.zip" -O /tmp/core.zip
              sudo unzip -o /tmp/core.zip -d /usr/local/bin/ v2ray
              sudo chmod +x /usr/local/bin/v2ray
              echo "âœ… $(v2ray version | head -1)"
              ;;
            *)
              echo "âŒ Unknown core: $PROXY_CORE"
              exit 1
              ;;
          esac

      - name: Tune System for Concurrency
        run: |
          sudo sysctl -w fs.file-max=2097152
          ulimit -n 1048576 || true
          sudo sysctl -w net.ipv4.ip_local_port_range="1024 65535"
          sudo sysctl -w net.core.somaxconn=65535
          sudo sysctl -w net.ipv4.tcp_tw_reuse=1
          sudo sysctl -w net.ipv4.tcp_fin_timeout=10
          sudo sysctl -w net.core.netdev_max_backlog=65535
          sudo sysctl -w net.core.rmem_max=16777216
          sudo sysctl -w net.core.wmem_max=16777216
          echo "âœ… System tuned"

      - name: Download Config Chunks
        uses: actions/download-artifact@v4
        with:
          name: config-chunks
          path: chunks/

      - name: Show Worker Info
        run: |
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "  WORKER ${{ matrix.chunk_id }} INFO"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "  CPU Cores: $(nproc)"
          echo "  Memory: $(free -h | grep Mem | awk '{print $2}')"
          echo "  Runner: ${{ runner.name }}"
          echo "  Chunk: chunks/chunk_${{ matrix.chunk_id }}.txt"
          echo "  Configs in chunk: $(wc -l < chunks/chunk_${{ matrix.chunk_id }}.txt)"
          echo "  Total configs: ${{ needs.master.outputs.total_configs }}"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: "Run Pipeline on Chunk ${{ matrix.chunk_id }}"
        env:
          RUNNER_NAME: ${{ runner.name }}
          PROXY_CORE: ${{ env.PROXY_CORE }}
        run: |
          echo "ï¿½ Worker ${{ matrix.chunk_id }} starting pipeline..."
          mkdir -p results/worker_${{ matrix.chunk_id }} logs

          ./configchecker test chunks/chunk_${{ matrix.chunk_id }}.txt ${{ matrix.chunk_id }} || true

          echo ""
          echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
          echo "Worker ${{ matrix.chunk_id }} finished"
          if [ -f results/worker_${{ matrix.chunk_id }}/worked.txt ]; then
            echo "Healthy configs: $(wc -l < results/worker_${{ matrix.chunk_id }}/worked.txt)"
          else
            echo "No healthy configs output"
          fi
          if [ -f results/worker_${{ matrix.chunk_id }}/status.json ]; then
            echo "Status:"
            cat results/worker_${{ matrix.chunk_id }}/status.json
          fi
          echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

      - name: Upload Worker Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: worker-result-${{ matrix.chunk_id }}
          path: results/worker_${{ matrix.chunk_id }}/
          retention-days: 1
          if-no-files-found: warn

      - name: Upload Worker Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-worker-${{ matrix.chunk_id }}
          path: logs/
          retention-days: 7
          if-no-files-found: ignore

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 3: COLLECTOR â€” Merge Results & Push
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  collector:
    name: "ğŸ”¶ Collector: Merge & Push"
    needs: [master, worker]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download Binary
        uses: actions/download-artifact@v4
        with:
          name: configchecker-binary

      - name: Make Binary Executable
        run: chmod +x ./configchecker

      - name: Download All Worker Results
        uses: actions/download-artifact@v4
        with:
          pattern: worker-result-*
          path: results/
          merge-multiple: false

      - name: Reorganize Results
        run: |
          echo "ï¿½ Organizing worker results..."
          # download-artifact creates: results/worker-result-0/files, results/worker-result-1/files
          # We need: results/worker_0/files, results/worker_1/files
          mkdir -p results_organized
          for dir in results/worker-result-*/; do
            if [ -d "$dir" ]; then
              # Extract chunk ID from directory name
              chunk_id=$(basename "$dir" | sed 's/worker-result-//')
              target="results_organized/worker_${chunk_id}"
              mkdir -p "$target"
              cp -r "$dir"* "$target/" 2>/dev/null || true
              echo "  worker-result-${chunk_id} â†’ worker_${chunk_id}"
            fi
          done
          rm -rf results
          mv results_organized results
          echo ""
          echo "Final structure:"
          find results/ -type f | head -50

      - name: "Merge Worker Results"
        env:
          RUNNER_NAME: ${{ runner.name }}
        run: |
          echo "ğŸ”€ Merging all worker results..."
          mkdir -p logs
          ./configchecker merge

      - name: Show Final Summary
        if: always()
        run: |
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           FINAL PIPELINE SUMMARY                â•‘"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"

          RUNNER_NAME=$(echo "${{ runner.name }}" | tr '/ :\\' '____')
          OUTPUT_DIR="configs/${RUNNER_NAME}"

          # Show worker statuses
          echo "â•‘                                                  â•‘"
          echo "â•‘  WORKER REPORTS:                                 â•‘"
          for status_file in results/worker_*/status.json; do
            if [ -f "$status_file" ]; then
              chunk_id=$(cat "$status_file" | grep -o '"chunk_id":[0-9]*' | cut -d: -f2)
              status=$(cat "$status_file" | grep -o '"status":"[^"]*"' | cut -d'"' -f4)
              healthy=$(cat "$status_file" | grep -o '"healthy_output":[0-9]*' | cut -d: -f2)
              processed=$(cat "$status_file" | grep -o '"processed":[0-9]*' | cut -d: -f2)
              duration=$(cat "$status_file" | grep -o '"duration_secs":[0-9.]*' | cut -d: -f2)
              echo "â•‘  Worker ${chunk_id}: ${status} | healthy=${healthy} | processed=${processed} | ${duration}s"
            fi
          done

          echo "â•‘                                                  â•‘"
          if [ -f "$OUTPUT_DIR/worked.txt" ]; then
            TOTAL_HEALTHY=$(wc -l < "$OUTPUT_DIR/worked.txt" 2>/dev/null || echo "0")
            FILE_SIZE=$(du -h "$OUTPUT_DIR/worked.txt" 2>/dev/null | cut -f1 || echo "0")
            echo "â•‘  TOTAL HEALTHY: ${TOTAL_HEALTHY} configs (${FILE_SIZE})"
          else
            echo "â•‘  TOTAL HEALTHY: 0 configs"
          fi
          echo "â•‘                                                  â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Upload All Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-collector-${{ github.run_id }}
          path: logs/
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload Summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-summary-${{ github.run_id }}
          path: |
            configs/*/summary.json
            configs/*/worked*.txt
          retention-days: 30
          if-no-files-found: ignore

      - name: Commit and Push Results
        if: always()
        run: |
          echo "ğŸ“¤ Pushing results to repository..."

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Pull latest
          git pull --rebase origin main || git pull --rebase origin master || true

          # Handle large files
          find configs/ -type f -size +95M 2>/dev/null | while read bigfile; do
            echo "âš ï¸ Splitting large file: $bigfile"
            split -b 90M "$bigfile" "${bigfile}_part_"
            rm "$bigfile"
          done

          # Stage results
          git add configs/ || true
          git add logs/ || true

          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            TIMESTAMP=$(date -u +%Y-%m-%d_%H-%M-%S)
            RUNNER_NAME=$(echo "${{ runner.name }}" | tr '/ :\\' '____')
            OUTPUT_DIR="configs/${RUNNER_NAME}"

            HEALTHY="0"
            if [ -f "$OUTPUT_DIR/worked.txt" ]; then
              HEALTHY=$(wc -l < "$OUTPUT_DIR/worked.txt" 2>/dev/null || echo "0")
            fi

            WORKERS="${{ needs.master.outputs.chunk_count || '?' }}"
            TOTAL_INPUT="${{ needs.master.outputs.total_configs || '?' }}"

            git commit -m "ğŸ”„ Pipeline: ${HEALTHY} healthy configs (${WORKERS} workers, ${TOTAL_INPUT} input) â€” ${TIMESTAMP}" \
              -m "Run: ${{ github.run_id }} | Workers: ${WORKERS} | Input: ${TOTAL_INPUT} | Output: ${HEALTHY}"

            # Retry push
            MAX_RETRIES=5
            RETRY=0
            while [ $RETRY -lt $MAX_RETRIES ]; do
              if git push origin HEAD; then
                echo "âœ… Pushed successfully"
                break
              else
                RETRY=$((RETRY + 1))
                echo "âš ï¸ Push retry $RETRY/$MAX_RETRIES..."
                sleep $((RETRY * 2))
                git pull --rebase origin main || git pull --rebase origin master || true
              fi
            done

            if [ $RETRY -eq $MAX_RETRIES ]; then
              echo "âŒ Push failed after $MAX_RETRIES retries"
              exit 1
            fi
          fi
